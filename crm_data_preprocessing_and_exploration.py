# -*- coding: utf-8 -*-
"""CRM Data preprocessing and exploration.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12QL7L6JH25d0c2cKK2LG6lkL72BoxutB

# CRM Data Preprocessing

## Variables
- **InvoiceNo**: Invoice number. The unique number of each transaction, namely The invoice. Aborted operation if it starts with C.
- **StockCode**: Product code. Unique number for each product.
- **Description**: Product name
- **Quantity**: Number of products. It expresses how many of the products on the invoices have been sold.
- **InvoiceDate**: Invoice date and time.
- **UnitPrice**: Product price (in GBP)
- **CustomerID**: Unique customer number
- **Country**: The country where the customer lives.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Loading the data with specified encoding
df = pd.read_csv("C:/Users/obypa/OneDrive/Drive/Data Science Portfolio/CRM Dataset.csv", encoding='latin1') 
print(df.head())

"""### Define a function to view the details of the dtaaset"""

#Let's get a fundamental understanding of the data's size, shape, and structure
# #Obtain the shape of the data
def check_df(dataframe):
    """
    This function analyzes a pandas DataFrame and prints various summaries.

    Args:
        dataframe (pandas.DataFrame): The DataFrame to be analyzed.
    """

    print("################ Shape ####################")
    print(f"Number of rows: {len(dataframe)}")
    print(f"Number of columns: {len(dataframe.columns)}")

    print("############### Columns ###################")
    print(dataframe.columns)

    print("############### Types #####################")
    print(dataframe.dtypes)

    print("############### Head ######################")
    print(dataframe.head())

    print("############### Tail ######################")
    print(dataframe.tail())

    print("############### Describe (excluding object types) ###################")
    print(dataframe.describe(exclude='object').T)

# Apply the function to the dataframe
check_df(df)

"""### Check for missing values"""

#check for missing values
df.isnull().sum()

"""Invoices that start with C indicate aborted sales/sales that did not go through. So drom the incoices starting with C, drop the missing rows in 'Description', and 'Customer ID'

### Drop rows with missing values
"""

# Drop rows with invoices starting with 'C'
df = df[~df['Invoice'].str.startswith('C')]

# Create a copy of the DataFrame before dropping missing values
df = df.dropna(subset=['Description', 'Customer ID'])

# Resetting the index after dropping rows
df.reset_index(drop=True, inplace=True)

df.isnull().sum()

"""### Check for outliers

The importance of checking for outliers in a dataset cannot be overstated. Outliers, which are data points significantly different from the majority of the data, serve as indicators of potential errors in data collection, entry, or processing. Addressing outliers is crucial for maintaining data quality and ensuring the integrity of statistical analyses, as outliers can heavily influence statistical measures like mean and standard deviation.
"""

def plot_outliers(df, column):
    """
    Plot outliers in a DataFrame column using a boxplot.

    Parameters:
        df (DataFrame): The DataFrame containing the column to check for outliers.
        column (str): The name of the column to check for outliers.
    """
    # Create a boxplot
    plt.figure(figsize=(8, 6))
    sns.boxplot(x=df[column])
    plt.title(f'Boxplot of {column}')

    # Calculate interquartile range (IQR)
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1

    # Define upper and lower bounds for outlier detection
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Find outliers
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]

    # Highlight outliers on the boxplot
    plt.plot([], marker='o', markersize=10, color='red', linestyle='none', label='Outlier')
    plt.scatter(outliers.index, outliers[column], marker='o', s=100, color='red')

    # Show legend
    plt.legend()

    # Show plot
    plt.show()

# Assuming df is your DataFrame
plot_outliers(df, 'Quantity')
plot_outliers(df, 'Price')

"""### Explore the categorical columns"""

def eda_categorical(df, column):
    """
    Perform exploratory data analysis (EDA) on a categorical variable in a DataFrame.

    Parameters:
        df (DataFrame): The DataFrame containing the categorical variable.
        column (str): The name of the categorical column to analyze.
    """
    # Count the frequency of each category
    category_counts = df[column].value_counts()

    # Sort the categories based on frequency counts in descending order
    category_counts = category_counts.sort_values(ascending=False)

    # Plot the distribution of the categorical variable
    plt.figure(figsize=(10, 6))
    sns.countplot(data=df, x=column, order=category_counts.index)
    plt.title(f'Distribution of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')

    # Annotate the bars with frequency counts
    for i, count in enumerate(category_counts):
        plt.text(i, count, str(count), ha='center', va='bottom')

    # Show plot
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

    # Print the frequency of each category
    print("Frequency of each category:")
    print(category_counts)

# Determine the top 25 countries based on frequency counts
top_countries = df['Country'].value_counts().head(20).index.tolist()

# Filter the DataFrame to include only rows corresponding to the top 25 countries
df_top_countries = df[df['Country'].isin(top_countries)]

# Apply the eda_categorical function to the 'Country' column of the filtered DataFrame
eda_categorical(df_top_countries, 'Country')

"""### Explore the numerical columns"""

def explore_numerical_columns(df):
    """
    Explore numerical columns in a DataFrame by summarizing descriptive statistics and plotting histograms.

    Parameters:
        df (DataFrame): The DataFrame containing the numerical columns.
    """
    # Select numerical columns excluding 'Customer ID'
    numerical_cols = [col for col in df.select_dtypes(include=['number']).columns if col != 'Customer ID']

    # Iterate over numerical columns
    for col in numerical_cols:
        # Print summary statistics
        print(f"Summary statistics for '{col}':")
        print(df[col].describe())
        print("\n")

# Example usage:
explore_numerical_columns(df)

"""### Time series analysis"""

def explore_datetime_column(df, column):
    """
    Explore a datetime column in a DataFrame by summarizing descriptive statistics and plotting a time series.

    Parameters:
        df (DataFrame): The DataFrame containing the datetime column.
        column (str): The name of the datetime column to explore.
    """
    # Convert 'Invoice' column to datetime
    df[column] = pd.to_datetime(df[column])

    # Print summary statistics
    print(f"Summary statistics for '{column}':")
    print(df[column].describe())
    print("\n")

    # Plot time series
    plt.figure(figsize=(10, 6))
    plt.plot(df[column], color='skyblue')
    plt.title(f'Time Series of {column}')
    plt.xlabel('Value')
    plt.ylabel('Date')
    plt.show()

# Example usage:
explore_datetime_column(df, 'InvoiceDate')

"""Analyze sales data and provide a clear summary of how many times each product was sold. It helps in understanding which products are popular and how well they are selling.

### Sales data visualisation
"""

# Group by "Description" and count the sales for each product
sales_per_product = df.groupby("Description").size().reset_index(name="Sales Count")

# Sort the result in descending order based on the "Sales Count" column
sales_per_product_sorted = sales_per_product.sort_values(by="Sales Count", ascending=False)

print("Number of sales for each product (sorted in descending order):")
print(sales_per_product_sorted)

# Select the top 20 products
top_20_products = sales_per_product_sorted.head(20)

# Generate a list of colors for the bars
colors = plt.cm.tab20(np.arange(len(top_20_products)))

# Plot the top 20 products with different colors
plt.figure(figsize=(10, 6))
plt.barh(top_20_products["Description"], top_20_products["Sales Count"], color=colors)
plt.xlabel('Sales Count')
plt.ylabel('Product Description')
plt.title('Top 20 Products by Sales Count')
plt.gca().invert_yaxis()  # Invert y-axis to show the highest count at the top
plt.show()

"""### Create a total price column

Calculate the total price of all items bought in each shopping transaction.  This total cost is then stored in a new column called "TotalPrice" in the dataset, making it easy to see how much was spent in each shopping trip.
"""

# total price per invoice
df["TotalPrice"] = df["Price"] * df["Quantity"]
df.head()

# Assuming df is your cleaned DataFrame
df.to_csv('cleanedCRM_data.csv', index=False)